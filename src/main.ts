import './style.css';
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import {
  loadModel,
  preprocessImage,
  processSegmentation,
  drawDetections
} from './utils/segmentation';
import { LABELS, COLORS } from './utils/labels';

// –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ WebGL –±—ç–∫–µ–Ω–¥
await tf.setBackend('webgl');
await tf.ready();
console.log('TensorFlow.js backend:', tf.getBackend());

let model: tf.GraphModel | null = null;
let isProcessing = false;
let currentMode: 'detection' | 'segmentation' = 'detection';
let currentThreshold = 0.5; // –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

const elements = {
  status: document.getElementById('status') as HTMLDivElement,
  imageUpload: document.getElementById('imageUpload') as HTMLInputElement,
  sourceImage: document.getElementById('sourceImage') as HTMLImageElement,
  canvas: document.getElementById('canvas') as HTMLCanvasElement,
  processing: document.getElementById('processing') as HTMLDivElement,
  inferenceTime: document.getElementById('inferenceTime') as HTMLDivElement,
  modeRadios: document.querySelectorAll('input[name="mode"]') as NodeListOf<HTMLInputElement>,
  showBoxes: document.getElementById('showBoxes') as HTMLInputElement,
  thresholdRange: document.getElementById('thresholdRange') as HTMLInputElement,
  thresholdValue: document.getElementById('thresholdValue') as HTMLSpanElement
};

async function initModel(): Promise<void> {
  try {
    console.log('–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO11n-seg...');
    const t0 = performance.now();
    model = await loadModel('./model/model.json');
    const t1 = performance.now();

    elements.status.textContent = `‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ (–∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ ${(t1 - t0).toFixed(0)}–º—Å)`;
    elements.status.classList.add('ready');
    elements.imageUpload.disabled = false;

    console.log('–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ');
  } catch (error) {
    console.error('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏:', error);
    elements.status.textContent = '‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏';
    elements.status.classList.add('error');
  }
}

// –î–û–ë–ê–í–õ–ï–ù–û: –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞
function handleModeChange(event: Event): void {
  const target = event.target as HTMLInputElement;
  currentMode = target.value as 'detection' | 'segmentation';
  console.log('–†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞:', currentMode);

  // –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ, –ø–µ—Ä–µ—Ä–∏—Å–æ–≤–∞—Ç—å
  if (elements.sourceImage.src && !isProcessing) {
    detectAndSegment(elements.sourceImage);
  }
}

async function handleImageUpload(event: Event): Promise<void> {
  const target = event.target as HTMLInputElement;
  const file = target.files?.[0];

  if (!file || !model || isProcessing) return;

  const reader = new FileReader();
  reader.onload = (e: ProgressEvent<FileReader>) => {
    if (!e.target?.result) return;

    elements.sourceImage.src = e.target.result as string;
    elements.sourceImage.onload = () => detectAndSegment(elements.sourceImage);
  };
  reader.readAsDataURL(file);
}

function handleDisplayOptionChange(): void {
  if (elements.sourceImage.src && !isProcessing) {
    detectAndSegment(elements.sourceImage);
  }
}

function handleThresholdChange(): void {
  const val = parseFloat(elements.thresholdRange.value);
  currentThreshold = val;
  elements.thresholdValue.textContent = val.toFixed(2);

  if (elements.sourceImage.src && !isProcessing) {
    detectAndSegment(elements.sourceImage);
  }
}


async function detectAndSegment(img: HTMLImageElement): Promise<void> {
  if (!model || isProcessing) return;

  isProcessing = true;
  elements.processing.style.display = 'block';
  elements.inferenceTime.style.display = 'none';
  elements.imageUpload.disabled = true;

  elements.modeRadios.forEach(radio => radio.disabled = true);
  // –î–û–ë–ê–í–õ–ï–ù–û: –û—Ç–∫–ª—é—á–∞–µ–º —á–µ–∫–±–æ–∫—Å—ã –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
  elements.showBoxes.disabled = true;

  const ctx = elements.canvas.getContext('2d');
  if (!ctx) return;

  elements.canvas.width = img.width;
  elements.canvas.height = img.height;
  ctx.drawImage(img, 0, 0);

  try {
    const totalStart = performance.now();

    const preprocessStart = performance.now();
    const { tensor, scale, padL, padT } = preprocessImage(img);
    const preprocessEnd = performance.now();

    const inferenceStart = performance.now();
    const predictions = model.execute(tensor) as tf.Tensor | tf.Tensor[];
    const inferenceEnd = performance.now();

    const postprocessStart = performance.now();
    const results = await processSegmentation(
      predictions,
      img.width,
      img.height,
      scale,
      padL,
      padT,
      currentThreshold,
      currentMode === 'segmentation'
    );
    const postprocessEnd = performance.now();

    const drawStart = performance.now();
    drawDetections(
      ctx,
      results,
      LABELS,
      COLORS,
      img.width,
      img.height,
      scale,
      padL,
      padT,
      currentMode === 'segmentation',
      elements.showBoxes.checked // –î–û–ë–ê–í–õ–ï–ù–û
    );
    const drawEnd = performance.now();

    const totalEnd = performance.now();

    const preprocessTime = preprocessEnd - preprocessStart;
    const inferenceTime = inferenceEnd - inferenceStart;
    const postprocessTime = postprocessEnd - postprocessStart;
    const drawTime = drawEnd - drawStart;
    const totalTime = totalEnd - totalStart;

    const modeEmoji = currentMode === 'segmentation' ? 'üé®' : 'üéØ';
    const modeName = currentMode === 'segmentation' ? '–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è' : '–î–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ';

    elements.inferenceTime.innerHTML = `
      ${modeEmoji} <strong>–†–µ–∂–∏–º: ${modeName}</strong><br>
      ‚ö° <strong>–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:</strong><br>
      ‚Ä¢ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: ${preprocessTime.toFixed(1)}–º—Å<br>
      ‚Ä¢ –ò–Ω—Ñ–µ—Ä–µ–Ω—Å: ${inferenceTime.toFixed(1)}–º—Å<br>
      ‚Ä¢ –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: ${postprocessTime.toFixed(1)}–º—Å<br>
      ‚Ä¢ –û—Ç—Ä–∏—Å–æ–≤–∫–∞: ${drawTime.toFixed(1)}–º—Å<br>
      ‚Ä¢ <strong>–í—Å–µ–≥–æ: ${totalTime.toFixed(1)}–º—Å</strong> | –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: ${results.length}
    `;
    elements.inferenceTime.style.display = 'block';

    console.log(`‚ö° –†–µ–∂–∏–º: ${modeName}
      - –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞: ${preprocessTime.toFixed(1)}–º—Å
      - –ò–Ω—Ñ–µ—Ä–µ–Ω—Å: ${inferenceTime.toFixed(1)}–º—Å
      - –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: ${postprocessTime.toFixed(1)}–º—Å
      - –û—Ç—Ä–∏—Å–æ–≤–∫–∞: ${drawTime.toFixed(1)}–º—Å
      - –í—Å–µ–≥–æ: ${totalTime.toFixed(1)}–º—Å`);
    console.log(`üéØ –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: ${results.length}`);

    tf.dispose([tensor, predictions]);
  } catch (error) {
    console.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:', error);
    alert('–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è');
  } finally {
    isProcessing = false;
    elements.processing.style.display = 'none';
    elements.imageUpload.disabled = false;
    elements.modeRadios.forEach(radio => radio.disabled = false);
    // –î–û–ë–ê–í–õ–ï–ù–û: –í–∫–ª—é—á–∞–µ–º —á–µ–∫–±–æ–∫—Å—ã –æ–±—Ä–∞—Ç–Ω–æ
    elements.showBoxes.disabled = false;
  }
}
// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
elements.imageUpload.addEventListener('change', handleImageUpload);
elements.modeRadios.forEach(radio => {
  radio.addEventListener('change', handleModeChange);
});
elements.showBoxes.addEventListener('change', handleDisplayOptionChange);
elements.thresholdRange.addEventListener('input', handleThresholdChange);


initModel();
